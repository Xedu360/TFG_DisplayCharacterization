{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d2d0220",
   "metadata": {},
   "source": [
    "# Characterization of Inverse Problem in Color Reproduction Using RFR and SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bfbdf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4a7d003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In your folder, there should be a TrainingRGB.xls, TrainingXYZ.xls, ValidationRGB.xls, and ValidationXYZ.xls.\n"
     ]
    }
   ],
   "source": [
    "print('In your folder, there should be a TrainingRGB.xls, TrainingXYZ.xls, ValidationRGB.xls, and ValidationXYZ.xls.')\n",
    "\n",
    "TrainingRGB = pd.read_excel('TrainingRGB.xls', header=None)\n",
    "TrainingXYZ = pd.read_excel('TrainingXYZ.xls', header=None)\n",
    "\n",
    "ValidationRGB = pd.read_excel('ValidationRGB.xls', header=None)\n",
    "ValidationXYZ = pd.read_excel('ValidationXYZ.xls', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b9e3b5",
   "metadata": {},
   "source": [
    "# RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83935fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_gradient_boosting_rfr(rf_regressor, samples, labels, hyperparameters, k=5):\n",
    "    best_mse = float('inf')\n",
    "    best_hyperparameters = {}\n",
    "    prev_mse = float('inf')\n",
    "    min_gradient_step = float('inf')\n",
    "    tolerance = 1  # Tolerancia para el criterio de parada\n",
    "\n",
    "    # Configurar K-Folds para la validación cruzada\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    while True:\n",
    "        # Muestrear hiperparámetros de los rangos\n",
    "        sampled_params = {\n",
    "            param: np.random.randint(param_range[0], param_range[1] + 1)\n",
    "            for param, param_range in hyperparameters.items()\n",
    "        }\n",
    "\n",
    "        rf_regressor.set_params(**sampled_params)\n",
    "\n",
    "        # Realizar la validación cruzada\n",
    "        mse_folds = []\n",
    "        for train_index, val_index in kf.split(samples):\n",
    "            X_train_fold, X_val_fold = samples.iloc[train_index], samples.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = labels.iloc[train_index], labels.iloc[val_index]\n",
    "\n",
    "            rf_regressor.fit(X_train_fold, y_train_fold)\n",
    "            predictions = rf_regressor.predict(X_val_fold)\n",
    "            mse_fold = mean_squared_error(y_val_fold, predictions)\n",
    "            mse_folds.append(mse_fold)\n",
    "\n",
    "        mse_mean = np.mean(mse_folds)\n",
    "\n",
    "        # Verificar si esta combinación de hiperparámetros es la mejor hasta ahora\n",
    "        if mse_mean < best_mse:\n",
    "            best_mse = mse_mean\n",
    "            best_hyperparameters = sampled_params\n",
    "\n",
    "        # Calcular el paso del gradiente\n",
    "        gradient_step = abs(prev_mse - mse_mean)\n",
    "        if gradient_step < min_gradient_step:\n",
    "            min_gradient_step = gradient_step\n",
    "\n",
    "        # Verificar el criterio de parada\n",
    "        if gradient_step < tolerance:\n",
    "            break\n",
    "\n",
    "        prev_mse = mse_mean\n",
    "\n",
    "    return best_hyperparameters, best_mse, min_gradient_step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c5ab1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many iterations do you want? 2\n",
      "Iteration 1/2 for Red channel\n",
      "Iteration 2/2 for Red channel\n",
      "Iteration 1/2 for Green channel\n",
      "Iteration 2/2 for Green channel\n",
      "Iteration 1/2 for Blue channel\n",
      "Iteration 2/2 for Blue channel\n",
      "\n",
      "Best results for RFR Red channel:\n",
      "Best RFR Hyperparameters: {'n_estimators': 83, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 1}\n",
      "Mean Squared Error for each RFR RGB channel: 50.10007569775935\n",
      "\n",
      "Best results for RFR Green channel:\n",
      "Best RFR Hyperparameters: {'n_estimators': 98, 'max_depth': 41, 'min_samples_split': 3, 'min_samples_leaf': 3}\n",
      "Mean Squared Error for each RFR RGB channel: 17.18352938393928\n",
      "\n",
      "Best results for RFR Blue channel:\n",
      "Best RFR Hyperparameters: {'n_estimators': 92, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 10}\n",
      "Mean Squared Error for each RFR RGB channel: 6.383870039085738\n",
      "Archivo 'Predictions_RFR.xlsx' creado con éxito.\n"
     ]
    }
   ],
   "source": [
    "# Crear diccionario para almacenar las predicciones\n",
    "predictions_dict = {}\n",
    "\n",
    "# Obtener el número de iteraciones del usuario\n",
    "iterations = int(input('How many iterations do you want? '))\n",
    "\n",
    "channels = ['Red', 'Green', 'Blue']\n",
    "best_results = {}\n",
    "\n",
    "for i, channel in enumerate(channels):\n",
    "    best_overall_hyperparameters = None\n",
    "    best_overall_mse = float('inf')\n",
    "    best_overall_min_gradient_step = None\n",
    "\n",
    "    for j in range(iterations):\n",
    "        print(f\"Iteration {j+1}/{iterations} for {channel} channel\")\n",
    "        \n",
    "        x_train = TrainingXYZ.iloc[:, :3]  \n",
    "        y_train = TrainingRGB.iloc[:, i] \n",
    "\n",
    "        x_val = ValidationXYZ.iloc[:, :3] \n",
    "        y_val = ValidationRGB.iloc[:, i] \n",
    "\n",
    "        # Inicializar Random Forest Regressor\n",
    "        random_forest = RandomForestRegressor(random_state=42)\n",
    "\n",
    "        # Definir el espacio de búsqueda de hiperparámetros (rangos)\n",
    "        hyperparameters = {\n",
    "            'n_estimators': [10, 100],  # Rango de 10 a 100\n",
    "            'max_depth': [10, 100],  # Rango de 10 a 100\n",
    "            'min_samples_split': [2, 10],  # Rango de 2 a 10\n",
    "            'min_samples_leaf': [1, 10]  # Rango de 1 a 10\n",
    "        }\n",
    "\n",
    "        # Explorar hiperparámetros y seleccionar el mejor resultado\n",
    "        best_hyperparameters, best_mse, min_gradient_step = custom_gradient_boosting_rfr(random_forest, x_train, y_train, hyperparameters, k=5)\n",
    "        \n",
    "        # Verificar si esta iteración tiene el mejor MSE hasta ahora\n",
    "        if best_mse < best_overall_mse:\n",
    "            best_overall_hyperparameters = best_hyperparameters\n",
    "            best_overall_mse = best_mse\n",
    "            best_overall_min_gradient_step = min_gradient_step\n",
    "\n",
    "    # Entrenar Random Forest con los mejores hiperparámetros obtenidos en todas las iteraciones\n",
    "    best_rf = RandomForestRegressor(**best_overall_hyperparameters, random_state=42)\n",
    "    best_rf.fit(x_train, y_train)\n",
    "\n",
    "    # Hacer predicciones en el conjunto de validación\n",
    "    predictions_RFR = best_rf.predict(x_val)\n",
    "    predictions_dict[channel] = predictions_RFR.round()\n",
    "    \n",
    "    # Guardar los mejores resultados\n",
    "    best_results[channel] = {\n",
    "        'Best Hyperparameters': best_overall_hyperparameters,\n",
    "        'Mean Squared Error': best_overall_mse,\n",
    "        'Minimum Gradient Step': best_overall_min_gradient_step\n",
    "    }\n",
    "\n",
    "# Crear el DataFrame con las predicciones\n",
    "predictions_df = pd.DataFrame(predictions_dict)\n",
    "\n",
    "# Guardar el DataFrame en un archivo Excel\n",
    "predictions_df.to_excel('Predictions_RFR.xlsx', index=False)\n",
    "\n",
    "# Mostrar los mejores resultados para cada canal\n",
    "for channel, result in best_results.items():\n",
    "    print(f\"\\nBest results for RFR {channel} channel:\")\n",
    "    print(\"Best RFR Hyperparameters:\", result['Best Hyperparameters'])\n",
    "    print(\"Mean Squared Error for each RFR RGB channel:\", result['Mean Squared Error'])\n",
    "\n",
    "print(\"File 'Predictions_RFR.xlsx' successfully created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cf0158",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c712e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_gradient_boosting_svr(svr_regressor, samples, labels, param_ranges, k=5):\n",
    "    best_mse = float('inf')\n",
    "    best_hyperparameters = {}\n",
    "    prev_mse = float('inf')\n",
    "    min_gradient_step = float('inf')\n",
    "    tolerance = 1  # Tolerancia para el criterio de parada\n",
    "\n",
    "    # Configurar K-Folds para la validación cruzada\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    while True:\n",
    "        # Muestrear hiperparámetros de los rangos\n",
    "        sampled_params = {\n",
    "            param: np.random.uniform(param_range[0], param_range[1])\n",
    "            for param, param_range in param_ranges.items() if param != 'kernel'\n",
    "        }\n",
    "\n",
    "        # Muestrear kernel de la lista de posibles kernels\n",
    "        sampled_params['kernel'] = np.random.choice(param_ranges['kernel'])\n",
    "\n",
    "        svr_regressor.set_params(**sampled_params)\n",
    "\n",
    "        # Realizar la validación cruzada\n",
    "        mse_folds = []\n",
    "        for train_index, val_index in kf.split(samples):\n",
    "            X_train_fold, X_val_fold = samples.iloc[train_index], samples.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = labels.iloc[train_index], labels.iloc[val_index]\n",
    "\n",
    "            svr_regressor.fit(X_train_fold, y_train_fold)\n",
    "            predictions = svr_regressor.predict(X_val_fold)\n",
    "            mse_fold = mean_squared_error(y_val_fold, predictions)\n",
    "            mse_folds.append(mse_fold)\n",
    "\n",
    "        mse_mean = np.mean(mse_folds)\n",
    "\n",
    "        # Verificar si esta combinación de hiperparámetros es la mejor hasta ahora\n",
    "        if mse_mean < best_mse:\n",
    "            best_mse = mse_mean\n",
    "            best_hyperparameters = sampled_params\n",
    "\n",
    "        # Calcular el paso del gradiente\n",
    "        gradient_step = abs(prev_mse - mse_mean)\n",
    "        if gradient_step < min_gradient_step:\n",
    "            min_gradient_step = gradient_step\n",
    "\n",
    "        # Verificar el criterio de parada\n",
    "        if gradient_step < tolerance:\n",
    "            break\n",
    "\n",
    "        prev_mse = mse_mean\n",
    "\n",
    "    return best_hyperparameters, best_mse, min_gradient_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae9f8e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many iterations do you want? 2\n",
      "Iteration 1/2 for Red channel\n",
      "Iteration 2/2 for Red channel\n",
      "Iteration 1/2 for Green channel\n",
      "Iteration 2/2 for Green channel\n",
      "Iteration 1/2 for Blue channel\n",
      "Iteration 2/2 for Blue channel\n",
      "\n",
      "Best results for SVR Red channel:\n",
      "Best SVR Hyperparameters: {'C': 1.0, 'epsilon': 0.46453976670634456, 'kernel': 'linear'}\n",
      "Mean Squared Error for each SVR RGB channel: 318.35765597526586\n",
      "\n",
      "Best results for SVR Green channel:\n",
      "Best SVR Hyperparameters: {'C': 1.0, 'epsilon': 0.24883025887488486, 'kernel': 'rbf'}\n",
      "Mean Squared Error for each SVR RGB channel: 190.56194140536527\n",
      "\n",
      "Best results for SVR Blue channel:\n",
      "Best SVR Hyperparameters: {'C': 1.0, 'epsilon': 0.306728178409453, 'kernel': 'rbf'}\n",
      "Mean Squared Error for each SVR RGB channel: 78.17538316786737\n",
      "File 'Predictions_SVR.xlsx' successfully created.\n"
     ]
    }
   ],
   "source": [
    "# Crear diccionario para almacenar las predicciones\n",
    "predictions_dict = {}\n",
    "\n",
    "# Obtener el número de iteraciones del usuario\n",
    "iterations = int(input('How many iterations do you want? '))\n",
    "\n",
    "channels = ['Red', 'Green', 'Blue']\n",
    "best_results = {}\n",
    "\n",
    "for i, channel in enumerate(channels):\n",
    "    best_overall_hyperparameters = None\n",
    "    best_overall_mse = float('inf')\n",
    "    best_overall_min_gradient_step = None\n",
    "\n",
    "    for j in range(iterations):\n",
    "        print(f\"Iteration {j+1}/{iterations} for {channel} channel\")\n",
    "        \n",
    "        x_train = TrainingXYZ.iloc[:, :3]  \n",
    "        y_train = TrainingRGB.iloc[:, i] \n",
    "\n",
    "        x_val = ValidationXYZ.iloc[:, :3] \n",
    "        y_val = ValidationRGB.iloc[:, i] \n",
    "\n",
    "        # Inicializar SVR Regressor\n",
    "        svm_regressor = SVR()\n",
    "\n",
    "        # Definir el espacio de búsqueda de hiperparámetros (rangos)\n",
    "        param_ranges = {\n",
    "            'C': [1, 15],        # Rango de 1 a 15\n",
    "            'epsilon': [0.1, 1],  # Rango de 0.1 a 1\n",
    "            'kernel': ['linear', 'poly', 'rbf', 'sigmoid']  # Lista de posibles kernels \n",
    "        }\n",
    "\n",
    "        # Explorar hiperparámetros y seleccionar el mejor resultado\n",
    "        best_hyperparameters, best_mse, min_gradient_step = custom_gradient_boosting_svr(svm_regressor, x_train, y_train, param_ranges, k=5)\n",
    "        \n",
    "        # Verificar si esta iteración tiene el mejor MSE hasta ahora\n",
    "        if best_mse < best_overall_mse:\n",
    "            best_overall_hyperparameters = best_hyperparameters\n",
    "            best_overall_mse = best_mse\n",
    "            best_overall_min_gradient_step = min_gradient_step\n",
    "\n",
    "    # Entrenar SVR con los mejores hiperparámetros obtenidos en todas las iteraciones\n",
    "    best_svr = SVR(**best_overall_hyperparameters)\n",
    "    best_svr.fit(x_train, y_train)\n",
    "\n",
    "    # Hacer predicciones en el conjunto de validación\n",
    "    predictions_SVR = best_svr.predict(x_val)\n",
    "    predictions_dict[channel] = predictions_SVR.round()\n",
    "    \n",
    "    # Guardar los mejores resultados\n",
    "    best_results[channel] = {\n",
    "        'Best Hyperparameters': best_overall_hyperparameters,\n",
    "        'Mean Squared Error': best_overall_mse,\n",
    "        'Minimum Gradient Step': best_overall_min_gradient_step\n",
    "    }\n",
    "\n",
    "# Crear el DataFrame con las predicciones\n",
    "predictions_df = pd.DataFrame(predictions_dict)\n",
    "\n",
    "# Guardar el DataFrame en un archivo Excel\n",
    "predictions_df.to_excel('Predictions_SVR.xlsx', index=False)\n",
    "\n",
    "# Mostrar los mejores resultados para cada canal\n",
    "for channel, result in best_results.items():\n",
    "    print(f\"\\nBest results for SVR {channel} channel:\")\n",
    "    print(\"Best SVR Hyperparameters:\", result['Best Hyperparameters'])\n",
    "    print(\"Mean Squared Error for each SVR RGB channel:\", result['Mean Squared Error'])\n",
    "\n",
    "print(\"File 'Predictions_SVR.xlsx' successfully created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aed6aad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
